\documentclass[12pt,a4paper,twocolumn]{article}
\usepackage[margin=2cm,columnsep=0.8cm]{geometry} 
\usepackage{setspace}                    
\usepackage{authblk}                      
\usepackage{graphicx}                    
\usepackage{subcaption}                 
\usepackage{float}                       
\usepackage{booktabs}                   
\usepackage{amsmath,amsfonts,amssymb}   
\usepackage{siunitx}                  
\usepackage[round,sort&compress]{natbib}
\usepackage[hyphens]{url}
\usepackage{hyperref}
\usepackage{breakurl}
\urlstyle{same}   
\usepackage{ragged2e}
\justifying               
\usepackage{caption}                    
\usepackage{fancyhdr}                   
\usepackage{xcolor}                    
\usepackage{libertine}
\usepackage{array}
\usepackage{threeparttable}
\usepackage{float}
\setlength{\parskip}{1.5ex}
\setlength{\parindent}{0pt}
\captionsetup{font=small,labelfont=bf}
\renewcommand{\bibfont}{\justifying} 
\usepackage{etoolbox}
\apptocmd{\thebibliography}{\justifying}{}{%
  \GenericError{}{Patching \thebibliography failed}{}{}
}


\fancyhf{}
\fancyhead[L]{\textit{Did they lie? Fake news detection in NLP}}  % Edit the running title (short title)
\fancyhead[R]{\thepage}

% For incoming students, feel free to use your home university here
\title{How fake is climate change? A comparison of fake news detection approaches.} % Pick your title (you may go creative here)
\author[1]{Braunegg, Florian} % Each author should be listed
\author[2]{Second Author}
\affil[1]{Graz University of Technology, Graz, Austria}
\affil[2]{University of Graz, Graz, Austria}
\date{\today}
\makeatletter
\g@addto@macro\UrlBreaks{\do\/\do-\do.\do?\do=\do&\do_\do:\do\#\do\%\do\\}
\makeatother
\begin{document}
\maketitle


\begin{abstract}
    Your abstract goes here. It should be a single paragraph of 150--250 words summarizing the report’s context, aims, methods, results, and conclusions.
    The entire paper should not exceed 6 pages (excluding limitations, ethical considerations, references, appendix).
    Please do not forget to fill out the contributions for each team member in the table.
\end{abstract}

\section{Introduction}
\label{sec:intro}
Fake news have become a major concern in contemporary political and social discourse. They contribute to the polarization and fragmentation of society \citep{au2022role} and, in extreme cases, may even pose a threat to public safety. This is exemplified by incidents such as Pizzagate, in which an armed man stormed a pizzeria in Washington, D.C., attempting to rescue non-existent children based on fabricated information \citep{2016pizzagate}. Due to their wide-ranging impact, addressing fake news effectively requires an approach that integrates both social and technical perspectives. While disciplines like psychology and sociology ofte explore how such misinformation spreads and shapes public opinion, computational fields, especially Natural Language Processing (NLP), provide tools to systematically analyze and detect such content. NLP enables the identification of linguistic patterns and contextual signals that are typical of deceptive or false information. Consequently, the reliable detection and classification of fake news remains a core challenge that NLP is uniquely equipped to address.

As part of the “Natural Language Processing” course at Graz University of Technology, we analyzed and classified fake news in three consecutive stages, each illustrating increasingly sophisticated NLP techniques for fake news detection.
\section{Related Work}
Fake news can be broadly understood as information presented in the form of news that is intentionally false and designed to mislead its audience. While the definition is not universally agreed upon, broader interpretations such as the one adopted in this paper treat fake news as an umbrella term that includes both misinformation (false information shared without intent to deceive) and disinformation (false information shared deliberately). In this broader perspective, any misleading or incorrect content presented as news, regardless of intent, may be classified as fake news (\citeauthor{deOliveira2021} \citeyear{deOliveira2021}; for a discussion of the terminology see \citeauthor{article} \citeyear{article}). Although instances of fake news can be traced as far back as 2100–1200 BC \citep{Roozenbeek2024Psychology}, scholarly interest in the phenomenon has only gained significant momentum in recent years \citep{info15120742}. Despite definitional differences, fake news have far-reaching consequences for social cohesion, public opinion, institutional trust, and political development. Prominent examples of these consequences include the election of U.S. President Donald Trump \citep{allcott2017social}, the Brexit referendum \citep{orlando2023posttruth}, and the COVID-19 crisis \citep{ferreira2022impact}, all of which are closely linked to the digitization of society.

Interest in fake news detection within the field of NLP began to grow significantly in the second decade of the 21st century. Early research on fake news detection primarily relied on traditional machine learning algorithms and, in some cases, rule-based systems. These systems operate by defining sets of rules or linguistic heuristics to classify articles. Rule-based systems generally exhibit lower accuracy compared to more advanced approaches, primarily due to their limited ability to capture contextual dependencies and adapt to dynamic linguistic variations. Consequently, they are prone to generating a high rate of false positives, especially when applied to sophisticated fake narratives or texts that deviate from their predefined rule configurations \citep{polu2024ai, repede2023comparison}. Applications of such rule-based approaches can be found, for example, in \citet{alotaibi2022rule}, who examined the spread of Arabic fake news during the COVID-19 pandemic, and in \citet{yuliani2019framework}, who developed a rule-based framework for hoax detection. When applied to larger or more complex text corpora, traditional machine learning algorithms such as Logistic Regression or Random Forest often outperform rule-based systems. Traditional machine learning algorithms rely on statistical modeling techniques and are capable of learning patterns directly from data. Although traditional machine learning algorithms are more flexible than rule-based systems, they still lack the ability to capture contextual information within text and depend heavily on manually engineered features and expert domain knowledge. Moreover, large amounts of data are often required to effectively train and fine tune these algorithms for specific tasks. Consequently, the performance and applicability of such models are highly dependent on how the problem is defined and on the quality of the manually engineered features they utilize \citep{polu2024ai, pittman2025truthtextmetaanalysismlbased}. Despite these limitations, comparative studies such as that by \citet{Sudhakar2022Prediction} demonstrate the considerable potential of traditional machine learning methods. The advent of deep learning marked a significant advancement in computational classification tasks, with models such as Convolutional Neural Networks (CNNs) and Long Short-Term Memory Networks (LSTMs) capable of learning hierarchical and sequential patterns directly from data. However, the introduction of the transformer architecture and the subsequent development of models such as BERT \citep{devlin-etal-2019-bert}, RoBERTa \citep{liu2019robertarobustlyoptimizedbert}, and GPT \citep{radford2018improving} represented a major breakthrough in natural language processing. Unlike earlier architectures, transformers leverage contextual embeddings and attention mechanisms to capture subtle dependencies and nuanced patterns in text that traditional machine learning models cannot handle. However, deep learning approaches still require substantial amounts of data, annotated datasets, and significant computational resources in order to achieve strong performance. Another major limitation of deep learning models is their lack of interpretability, as they often function as black box systems whose internal decision-making processes are difficult to trace or explain \citep{polu2024ai, pittman2025truthtextmetaanalysismlbased}. In response to the limitations of individual approaches, recent research has proposed hybrid models for fake news detection that aim to combine the strengths of different techniques. \citet{Nasir2021Hybrid} for example proposed a CNN-RNN hybrid model and \citet{Albahar2021Hybrid} an SVM-RNN-BI-GT hybrid model for fake news detection.

\section{Materials and Methods}
\label{sec:methods}
Our dataset consists of 150 articles of both fake and real news, collected and provided by students and faculty at Graz University of Technology. For stages two and three, we implemented all code using Python. In the first stage, we manually evaluated all articles to create a labeled dataset for the subsequent stages and to gain an initial understanding of how fake news is written. In doing so, we followed the definition of fake news outlined earlier in the related work section.

In the second stage, we used pandas \citep{Pandas} to import the dataset and the Random Forest classifier from scikit-learn \citep{scikit-learn} to classify 150 articles as fake or real. We specifically chose features that are straightforward and interpretable, aiming to make our results easily understandable and transparent. These include part-of-speech tags (PoS-tags), fake claim matches, emotion scores, readability and difficulty measures, as well as grammatical and spelling errors, all extracted separately for headlines and body text.

PoS-tags were extracted using spaCy \citep{spaCy}, which also handled the tokenization. We restricted the PoS-tags to the 17 universal PoS categories defined in the Universal Dependencies framework \citep{universaldependencies} to extract easily interpretable logical units. The frequency of each tag was calculated relative to the total number of tokens in the article.

Our fake claim detection process was based on a knowledge base consisting of two components: entities (with aliases) and concise fake claims. To reduce bias toward our articles and due to time constraints, all entries were extracted using a one-shot prompt from GPT-4o mini \citep{openai_gpt4o_mini}. Both elements were tokenized and lowercased using spaCy to facilitate matching; claims were further lemmatized and filtered with spaCy’s stopword list. Entity matching in the articles was performed using spaCy’s PhraseMatcher. For each matched entity, all sentences from the article containing it were collected, lowercased, lemmatized, and cleaned of non-alphanumeric tokens and stopwords. Each entity in multi-entity sentences was checked separately. Since exact wording was not guaranteed, synonyms were retrieved via WordNet from NLTK \citep{NLTK}, then also lemmatized and lowercased. To enhance fuzzy matching, we used Python’s SequenceMatcher with a similarity threshold of 0.9 for entities and 0.7 for claims. Each entity, claim pair was counted only once per article, regardless of the number of occurrences. The final feature was calculated as the number of unique matched pairs divided by the total number of sentences in the article.

To detect emotions in the text, we compared all tokens extracted with spaCy against an extended version of the NRC Word–Emotion Association Lexicon \citep{emotions}, as provided by \citet{NRClex}. For each article, we calculated the relative frequency of each emotion in proportion to all emotion-bearing terms. Based on insights from our manual analysis in Stage 1, we focused on four prevalent emotions: anger, anticipation, fear, and sadness.

To assess article readability, we used the Flesch Reading Ease \citep{flesch} and the Automated Readability Index (ARI) \citep{senter_smith_1967}, both calculated with textstat \citep{textstat}. The Flesch score ranges from 0 (very difficult) to 100 (very easy), while the ARI reflects U.S. grade levels. Additionally, we measured word difficulty as the proportion of difficult words, based on the list from \citet{chall1995readability}.

Grammatical and spelling errors were detected using LanguageTool for Python \citep{ltp}. We calculated the number of detected issues relative to the total word count as an additional feature.

To determine the optimal feature set and model parameters, we used an 80/20 holdout split. The models hyperparameters were tuned using GridSearchCV from scikit-learn with accuracy as the evaluation metric, and overfitting was controlled with RepeatedStratifiedKFold (five folds, three repeats). Feature selection was refined using the Boruta algorithm \citep{boruta1, boruta2}, and feature importance was assessed by the mean decrease in impurity from the Random Forest implementation. We decided to retain all features above the 90th percentile in importance. The final model performance was evaluated using repeated holdout validation across 1000 random splits, reporting accuracy, precision, recall, F1-score, feature importances, and mean feature values.
\section{Results}
\label{sec:results}
Using the Boruta algorithm described in the last section, we identified 13 features as statistically significant predictors for distinguishing fake from real news with our Random Forest classifier. Table 1 presents the evaluation metrics of the model in comparison to a mean baseline.
\begin{table}[h!]
    \renewcommand{\arraystretch}{1.3}
    \centering
    \caption{Evaluation metrics (mean and 95\% CI) over 1000 random splits.}
    \label{tab:evaluation_metrics}
    \begin{tabular}{|>{\centering\arraybackslash}m{2.5cm}|>{\centering\arraybackslash}m{4.5cm}|}
        \hline
        \multicolumn{2}{|c|}{\textbf{Random Forest Classifier}} \\
        \hline
        Accuracy & 0.842\ (0.837-0.846) \\
        Precision & 0.848\ (0.844-0.852) \\
        Recall & 0.841\ (0.836-0.845) \\
        F1-Score & 0.840\ (0.835-0.844) \\
        \hline
        \multicolumn{2}{|c|}{\textbf{Mean Baseline}} \\
        \hline
        Accuracy & 0.506\ (0.500-0.512) \\
        Precision & 0.505\ (0.499-0.511) \\
        Recall & 0.504\ (0.498-0.510) \\
        F1-Score & 0.500\ (0.494-0.506) \\
        \hline
    \end{tabular}
\end{table}
\newline
The Random Forest classifier achieved a mean accuracy of 0.839 (0.834–0.843), with similarly high precision, recall, and F1-scores. In contrast, the baseline only reached around 0.5 on these metrics, highlighting the added value of our feature set.

To assess the contribution of each selected feature to the model’s predictive performance, Table 2 presents their relative importance and mean values.
\begin{table}[h!]
    \renewcommand{\arraystretch}{1.3}
    \centering
    \begin{threeparttable}
        \caption{Top 13 features ranked by mean decrease in impurity (MDI) and their mean values for fake and real news over 1000 random splits.}
        \label{tab:feature_importance}
        \begin{tabular}{|>{\centering\arraybackslash}m{3.25cm}|>{\centering\arraybackslash}m{1.25cm}|>{\centering\arraybackslash}m{1.25cm}|>{\centering\arraybackslash}m{1.25cm}|}
            \hline
            \textbf{Feature} & \textbf{MDI} & \textbf{Fake} & \textbf{Real} \\
            \hline
            Proper noun ratio in headline & 0.167 & 0.316 & 0.125 \\
            Noun ratio in headline & 0.128 & 0.142 & 0.292 \\
            Anticipation word ratio & 0.078 & 0.082 & 0.107 \\
            Verb ratio in headline & 0.077 & 0.085 & 0.141 \\
            Subordinating conjunction ratio & 0.074 & 0.021 & 0.018 \\
            Punctuation ratio in headline & 0.073 & 0.134 & 0.073 \\
            Adjective ratio & 0.071 & 0.083 & 0.072 \\
            Verb ratio & 0.068 & 0.101 & 0.111 \\
            ARI in headline & 0.066 & 10.87 & 8.97 \\
            Noun ratio & 0.060 & 0.212 & 0.225 \\
            Proper noun ratio & 0.053 & 0.061 & 0.068 \\
            Pronoun ratio & 0.050 & 0.044 & 0.035 \\
            Determiner ratio in headline & 0.037 & 0.050 & 0.020 \\
            \hline
        \end{tabular}
        \vspace{0.3em}
        {\raggedright\footnotesize MDI: Mean Decrease in Impurity.\par}
    \end{threeparttable}
\end{table}
The headline-based PoS-tag ratios and the ARI together account for nearly 60\% of the overall feature importance. Among emotion features, only anticipation contributes meaningfully, and it is more prevalent in real news. Grammatical function words, error counts, and the knowledge-base feature have negligible impact. Feature means further show that real news tend to have higher noun and verb ratios and more readable headlines, whereas fake news rely more on proper nouns, pronouns, adjectives, determiners and punctuation.
\section{Discussion}
\label{sec:discussion}
Our qualitative analysis in Stage 1 revealed that fake news articles are characterized by sensational and sometimes very emotionally charged narratives, frequent misinterpretations of sources, and the advancement of one sided or even conspiratorial viewpoints. This is often mirrored in the headlines of the articles, which serve as eye catching hooks, featuring named individuals, organizations, or groups to lend authority or appeal to emotions, or employ mockery and ridicule to delegitimize opposing viewpoint.

Rather than relying primarily on accepted facts, fake news articles achieve their effect through provocative, informal rhetorical devices that shape their style. In contrast, real news tends to exhibit a more formal, informative, and reportative style, as reflected in the different PoS-tag patterns and the ARI captured by our Random Forest classifier. Notably, in the context of climate change reporting, real news articles also place greater emphasis on anticipation, signaling a forward looking and constructive framing of information. These stylistic contrasts, while most apparent in the headlines, are not limited to them but extend consistently throughout the body of the text. 

Recognizing these recurring stylistic and narrative patterns proved crucial for feature engineering and for the effective use of our traditional machine learning method. Since such approaches depend on explicitly defined features, our qualitative analysis provided valuable grounding in what to look for beyond surface level content. The resulting set of descriptive features enabled us to capture the relevant stylistic and rhetorical patterns with only twelve features, demonstrating that a compact, well-chosen feature set can provide robust performance for fake news detection in our domain.

While we included a rule-based knowledge base for explicit factual errors, this approach quickly reached its limits. The changing and creative ways misinformation is expressed made it difficult for our system to keep pace, especially regarding subtle or stylistic strategies. Our attempts to make the system more flexible ultimately resulted in an increase of false positives, underscoring the need for adaptable, data-driven models that better reflect the complexity of real world texts.


\section{Conclusion}
\label{sec:conclusion}
Summarize the key findings and implications (design your report that one get the main insights from reading abstract/introduction/conclusions and glancing at the illustrations). 
Suggest future research (very briefly).


% Everything up here counts for the page limit 
\newpage

\section*{Limitations}
Since our dataset comprises only 150 articles, the models are highly tailored to this small sample. Additionally, the data was collected over a short period, focusing primarily on recent fake news related to climate change. To improve especially the external validity and generalizability of our results, a larger dataset covering a broader range of topics and a longer collection timeframe would have been necessary.

As outlined in the methodology, we also relied on GPT-4o mini to generate information for our knowledge base in Stage Two. While GPT-4o mini is a powerful tool for producing general statements about fake news, it lacks the depth and nuance that manual data collection can offer. As a result, the knowledge base used for our rule-based algorithm, whose outputs served as features for the Random Forest classifier, remained quite generic and therefore less robust.

\section*{Contributions}
% Add here a list of the individual contributions per team member

\captionsetup{justification=raggedright, singlelinecheck=false, skip=20pt}
\captionof{table}{Contribution}
\vspace{1em}
\label{tab:evaluation_metrics}
\begin{center}
\begin{tabular}{|>{\centering\arraybackslash}m{2.5cm}|>{\centering\arraybackslash}m{4.5cm}|}
    \hline
    \textbf{Name} & \textbf{Contribution} \\
    \hline
    Florian Braunegg &
        Stage0,\par
        Stage1,\par
        Stage2,\par
        Introduction,\par
        Related Work,\par
        Methods \& Materials (Materials, Stage1, Stage2),\par
        Results (Stage1, Stage2),\par
        Discussion (Stage1, Stage2),\par
        Limitations,\par
        Acknowledgments
    \\
    \hline
    Another Name & Did not even care to show up. \\
    \hline
\end{tabular}
\end{center}
\vspace{1em}
\section*{Acknowledgments}
This paper was written as part of the “Natural Language Processing” course held during the summer semester 2025 at Graz University of Technology. The materials used were collected by the course participants and individuals affiliated with the university. No monetary resources were involved in the preparation of this paper.

\bibliographystyle{plainnat}
\bibliography{bibliography}

\appendix

\section{Appendix - GPT-4o mini prompt (Stage 2)}

Prompt:
Write fake news claims about climate change using the exact same structure as the example given. Do not alter the format at any time. Example: \{
  "entity": "Paris Agreement",
  "aliases": [ "PA", "Paris Accord" ],
  "claims": [
    "aims to limit global warming to 4°C",
    "was signed by China alone",
    "has no legal force"
  ]
\}





\section{Appendix - Usage of AI}
Beside the mentioned use of GPT-4o mini in the text above, "AI" was only used for grammatical and structural corrections. All contents and ideas presented in this paper, where not explicitly marked as the intellectual property of other authors, are solely the result of the authors’ own work.


\begin{figure}
    \centering
        \includegraphics[width=0.7\linewidth]{example-image}
    \caption{Example figure caption. Please consider to explain to the reader, what is depicted}
    \label{fig:example}
\end{figure}


\end{document}
