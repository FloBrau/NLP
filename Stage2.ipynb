{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea666b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: spacy in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.8.6)\n",
      "Requirement already satisfied: textstat in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.7.7)\n",
      "Requirement already satisfied: language-tool-python in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.9.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: boruta in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.4.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (0.15.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.11.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (80.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<8.2,>=8.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: pyphen in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from textstat) (0.17.2)\n",
      "Requirement already satisfied: cmudict in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from textstat) (1.0.32)\n",
      "Requirement already satisfied: psutil in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from language-tool-python) (6.0.0)\n",
      "Requirement already satisfied: toml in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from language-tool-python) (0.10.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: importlib-metadata>=5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cmudict->textstat) (8.7.0)\n",
      "Requirement already satisfied: importlib-resources>=5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cmudict->textstat) (6.5.2)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from importlib-metadata>=5->cmudict->textstat) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->spacy) (2.1.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------- ------------------------------ 2.9/12.8 MB 15.2 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 5.5/12.8 MB 14.6 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.2/12.8 MB 14.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 12.3/12.8 MB 14.8 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 14.6 MB/s eta 0:00:00\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "<frozen runpy>:128: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install pandas spacy textstat language-tool-python numpy scikit-learn boruta nltk\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m nltk.downloader wordnet omw-1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86b06293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import spacy\n",
    "import textstat\n",
    "import language_tool_python\n",
    "import numpy as np\n",
    "import random\n",
    "import nltk\n",
    "from spacy.tokens import Doc\n",
    "from spacy.matcher import PhraseMatcher          \n",
    "from spacy.lang.en.stop_words import STOP_WORDS \n",
    "from difflib import SequenceMatcher\n",
    "from nltk.corpus import wordnet as wn\n",
    "from urllib.request import urlopen\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from boruta import BorutaPy\n",
    "\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "language_tool = language_tool_python.LanguageTool(\"en-US\")\n",
    "#loading the nrc_en lexicon manually as the NRCLex 4.0 is very buggy\n",
    "url = \"https://raw.githubusercontent.com/DemetersSon83/NRCLex/refs/heads/master/nrc_en.json\" \n",
    "with urlopen(url) as re:\n",
    "    lexicon = json.load(re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "599ddc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_articles (filepath: str) -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"\n",
    "        Load the articles as a pandas DF\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    article = []\n",
    "    with open(filepath, \"r\", encoding = \"utf-8\") as file:\n",
    "        for line in file:\n",
    "            line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            article.append(json.loads(line))\n",
    "\n",
    "    return pd.DataFrame(article)      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b245580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_texts (articles: list[str]) -> list[Doc]:\n",
    "\n",
    "    \"\"\"\n",
    "        Use \"en_core_web_sm\" model on df[\"Text\"] and df[\"Title]\n",
    "     \n",
    "    \"\"\"\n",
    "\n",
    "    return list(nlp.pipe(articles))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def POStagging (articles: list[Doc], df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"\n",
    "        Counting and processing POS-Tags\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #filter POS-tags we want\n",
    "    #we stick with universal POS-tags for now\n",
    "    #https://github.com/explosion/spaCy/blob/master/spacy/glossary.py\n",
    "    universal_tags = [\"ADJ\", \"ADP\", \"ADV\", \"AUX\",  \"CCONJ\", \"DET\", \"INTJ\", \"NOUN\",\n",
    "                      \"NUM\", \"PART\", \"PRON\", \"PROPN\", \"PUNCT\", \"SCONJ\", \"SYM\", \"VERB\", \"X\"]\n",
    "    \n",
    "    \n",
    "    #retrieving the IDs of the relevant POS-tags\n",
    "    tag_ids = {tag: nlp.vocab.strings[tag] for tag in universal_tags}\n",
    "\n",
    "\n",
    "    temp_df_list = []\n",
    "    for article in articles:\n",
    "\n",
    "\n",
    "        #count all tokens (without space-tokens)\n",
    "        total_tokens = sum(1 for token in article if not token.is_space)\n",
    "\n",
    "\n",
    "        #counting all POS-tags\n",
    "        pos_counts = article.count_by(spacy.attrs.POS)\n",
    "\n",
    "\n",
    "        #adding the POS-Tags as percentage of the total tokens + total count \n",
    "        inner_temp = {}\n",
    "        for tag, tag_id in tag_ids.items():\n",
    "            counter = pos_counts[tag_id] if tag_id in pos_counts else 0\n",
    "            inner_temp[f\"{tag.lower()}_perc\"] = counter / total_tokens if total_tokens else 0 \n",
    "        temp_df_list.append(inner_temp)  \n",
    "\n",
    "\n",
    "    #create a pd DF with the same index as df\n",
    "    df_features = pd.DataFrame(temp_df_list, index = df.index)\n",
    "    return pd.concat([df,df_features], axis = 1)     \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def emotions_nrc (articles: list[Doc], df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    \"\"\" \n",
    "        Counting and processing the emotions in the articles \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #filtering all emotions tags   \n",
    "    emotion_tags = [\"anger\", \"anticipation\", \"fear\", \"sadness\"]\n",
    "    \n",
    "\n",
    "    #the following code is inspired by the NRCLex module by metalcorebear:\n",
    "    #i only recreate parts of the code as the module itselfe tends to cause problems \n",
    "    #source: https://pypi.org/project/NRCLex/\n",
    "\n",
    "\n",
    "    lex_keys = set(lexicon.keys())\n",
    "    temp_df_list = []\n",
    "    for article in articles:\n",
    "\n",
    "\n",
    "        #filtering and processing all relevant tokens\n",
    "        affect_list = []\n",
    "        for tok in article:\n",
    "            if not tok.is_alpha:\n",
    "                continue\n",
    "            orig = tok.lower_\n",
    "            if orig in lex_keys:    \n",
    "                affect_list.extend(lexicon[orig])    \n",
    "\n",
    "\n",
    "        #creating relevant counters\n",
    "        freq_counter = Counter()\n",
    "        for emo in affect_list:\n",
    "            freq_counter[emo] += 1\n",
    "        total_emotions = sum(freq_counter.values()) or 1        \n",
    "\n",
    "\n",
    "        #adding the emotions as percentage of the total emotinos + total count \n",
    "        inner_temp = {}\n",
    "        for emotion in emotion_tags:\n",
    "            emotion_counter = freq_counter[emotion] if emotion in freq_counter else 0\n",
    "            inner_temp[f\"{emotion.lower()}_perc\"] = emotion_counter / total_emotions\n",
    "        temp_df_list.append(inner_temp)    \n",
    "\n",
    "\n",
    "    #create a pd DF with the same index as df\n",
    "    df_features = pd.DataFrame(temp_df_list, index = df.index)\n",
    "    return pd.concat([df,df_features], axis = 1)     \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def KB_detection (articles: list[Doc], df: pd.DataFrame, kb: str) -> pd.DataFrame:\n",
    "    \n",
    "    \"\"\"\n",
    "        Wrong claims detection with our KB\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    with open(kb, \"r\", encoding = \"utf-8\") as file:\n",
    "        data_to_be_cleaned = json.load(file)\n",
    "\n",
    "\n",
    "    #here we clean our KB, to make sure there are no leading or trailing whitespaces\n",
    "    cleaned_data = []\n",
    "    for item in data_to_be_cleaned:\n",
    "        cleaned_data.append({\n",
    "\n",
    "            \"entity\": item[\"entity\"].strip(),\n",
    "            \"aliases\": [alias.strip() for alias in item[\"aliases\"]],\n",
    "            \"claims\":  [claim.strip() for claim in item[\"claims\"]]\n",
    "\n",
    "        })    \n",
    "\n",
    "\n",
    "\n",
    "    #create phrases from the KB, we are looking for in the text\n",
    "    matcher = PhraseMatcher(nlp.vocab, attr = \"LOWER\")\n",
    "    for item in cleaned_data:\n",
    "        pattern = [nlp.make_doc(item[\"entity\"])]\n",
    "        for alias in item[\"aliases\"]:\n",
    "            pattern.append(nlp.make_doc(alias))\n",
    "        matcher.add(item[\"entity\"], pattern)\n",
    "\n",
    "\n",
    "\n",
    "    temp_df_list = []\n",
    "\n",
    "    \n",
    "    for article in articles:\n",
    "        sent_lems = []\n",
    "        #create a lematized. lowered and stop-words-filtered version of every sentence \n",
    "        for sent in article.sents:\n",
    "            sent_lems.append([tok.lemma_.lower() for tok in sent if (tok.is_alpha or tok.is_digit) and tok.lemma_.lower() not in STOP_WORDS])\n",
    "        \n",
    "\n",
    "        sent_claims = [set() for _ in sent_lems]\n",
    "        #apply the matcher we created and extract the parts in the article\n",
    "        ents = {article[start:end].text for _, start, end in matcher(article)}\n",
    "        matched_pairs_article = set()\n",
    "\n",
    "        #KB etentity lookup with a fuzzy matcher just if there are some differences (should not be)\n",
    "        for ent_text in ents:\n",
    "            item =  None\n",
    "            for entry in cleaned_data:\n",
    "                for name in [entry[\"entity\"]] + entry[\"aliases\"]:\n",
    "                    if SequenceMatcher(None, ent_text.lower(), name.lower()).ratio() >= 0.7:\n",
    "                        item = entry\n",
    "                        break \n",
    "                if item:\n",
    "                    break\n",
    "            if item is None:\n",
    "                continue\n",
    "\n",
    "        \n",
    "            #now we check the fake claims from our KB\n",
    "            for claim in item[\"claims\"]:\n",
    "\n",
    "\n",
    "                #here we lemmatize, lower and filter the KB claims\n",
    "                temp_claim = nlp(claim)\n",
    "                claim_lem_stop_low = [tok.lemma_.lower() for tok in temp_claim if (tok.is_alpha or tok.is_digit)\n",
    "                                    and tok.lemma_.lower() not in STOP_WORDS]\n",
    "                if len(claim_lem_stop_low) <= 1:\n",
    "                    continue\n",
    "\n",
    "                \n",
    "                #now we utilize wordnet to find synonyms and also lemmatize and lower them\n",
    "                syns = set()\n",
    "                for term in claim_lem_stop_low:\n",
    "                    for syn in wn.synsets(term):\n",
    "                        for lemma in syn.lemmas():\n",
    "                            syns.add(lemma.name().lower())\n",
    "\n",
    "\n",
    "                #calculate if a word is a hit with fuzzy matching ()\n",
    "                for num, sent_lemmas in enumerate(sent_lems):\n",
    "                    base_hits = sum(1 for term in claim_lem_stop_low\n",
    "                        if any(SequenceMatcher(None, term, lem).ratio() >= 0.5 for lem in sent_lemmas))\n",
    "                    syn_hits = sum(1 for syn in syns\n",
    "                                   if any(SequenceMatcher(None, syn, lem).ratio() >= 0.5 for lem in sent_lemmas))\n",
    "\n",
    "                    #now for the combination\n",
    "                    if syn_hits + base_hits >= 2:\n",
    "                        if (item[\"entity\"], claim) not in matched_pairs_article:\n",
    "                            matched_pairs_article.add((item[\"entity\"], claim))\n",
    "                        sent_claims[num].add((item[\"entity\"], claim))\n",
    "\n",
    "        total_claims_matched = sum(len(sent) for sent in sent_claims)\n",
    "        temp_df_list.append(total_claims_matched / len(sent_lems))\n",
    "\n",
    "\n",
    "    df_features = pd.DataFrame({\"fake_match_count\": temp_df_list}, index = df.index)\n",
    "    df_features.fillna(0, inplace=True)\n",
    "    return pd.concat([df,df_features], axis = 1)     \n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "def readability_and_difficulty_scores (articles: list[str], df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"\n",
    "    Processing fleschs readability scores and difficult words\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "\n",
    "    temp_df_list = []\n",
    "\n",
    "    for article in articles:\n",
    "        inner_temp = {\n",
    "\n",
    "            #different difficulties\n",
    "            #https://github.com/kupolak/textstat/blob/master/README.md#spache-readability-formula (for scales)\n",
    "            \"flesch_reading_ease\": textstat.flesch_reading_ease(article),\n",
    "            \"automated_readbility_index\": textstat.automated_readability_index(article),\n",
    "\n",
    "\n",
    "            #difficult perc of total words\n",
    "            \"difficult_words_perc\": textstat.difficult_words(article) / textstat.lexicon_count(article,\n",
    "                                                                                    removepunct = True)\n",
    "\n",
    "        }\n",
    "        temp_df_list.append(inner_temp)\n",
    "\n",
    "\n",
    "    #create a pd DF with the same index as df\n",
    "    df_features = pd.DataFrame(temp_df_list, index = df.index)\n",
    "    return pd.concat([df,df_features], axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Error_check (articles: list[str], df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    \"\"\" \n",
    "        Counting and processing the grammar and spelling check\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    temp_df_list = []\n",
    "    for article in articles:\n",
    "\n",
    "        matches = language_tool.check(article)\n",
    "\n",
    "        #extract the misspellings and grammatical mistakes\n",
    "        only_s = [entry for entry in matches if entry.ruleIssueType == \"misspelling\"]    \n",
    "        only_g = [entry for entry in matches if entry.ruleIssueType == \"grammar\"]\n",
    "        total_s = len(only_s)\n",
    "        total_g = len(only_g)  \n",
    "        total_words = textstat.lexicon_count(article, removepunct = True)\n",
    "\n",
    "\n",
    "\n",
    "        #append the relative amount\n",
    "        inner_temp = {\n",
    "\n",
    "            \"misspellings_perc\": total_s / total_words,\n",
    "            \"grammar_perc\": total_g / total_words\n",
    "\n",
    "        }\n",
    "        temp_df_list.append(inner_temp)    \n",
    "\n",
    "\n",
    "\n",
    "    #create a pd DF with the same index as df\n",
    "    df_features = pd.DataFrame(temp_df_list, index = df.index)\n",
    "    return pd.concat([df,df_features], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11169e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_df (df: pd.DataFrame, df2: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"\n",
    "        Connect the text and headline df\n",
    "    \"\"\"\n",
    "\n",
    "    #change column names for the headlines\n",
    "    df2_copy = df2.copy()\n",
    "    df2_copy.columns = [\"hl_\" + col for col in df2_copy.columns]\n",
    "\n",
    "    return pd.concat([df, df2_copy], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26333732",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#load\n",
    "file_path = Path(\"C:/Users/Admin/Desktop/Uni/CSS/NLP/without_assessment.jsonl\")\n",
    "kb = \"KB.json\"\n",
    "df = load_articles(str(file_path))\n",
    "df2 = df.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Text\n",
    "\n",
    "\n",
    "#prepare text\n",
    "texts = df[\"Text\"].tolist()\n",
    "docs  = process_texts(texts)\n",
    "\n",
    "\n",
    "#POS- and NERfeat\n",
    "df = POStagging(docs, df)\n",
    "df = KB_detection(docs, df, kb)\n",
    "\n",
    "\n",
    "#add emotions\n",
    "df = emotions_nrc(docs, df)\n",
    "\n",
    "\n",
    "#readability and difficulty\n",
    "df = readability_and_difficulty_scores(texts, df)\n",
    "\n",
    "\n",
    "#grammar and spelling errors\n",
    "df = Error_check(texts, df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Headlines\n",
    "\n",
    "\n",
    "#prepare text\n",
    "titels = df2[\"Title\"].tolist()\n",
    "docs  = process_texts(titels)\n",
    "\n",
    "\n",
    "#POS- and NERfeat\n",
    "df2 = POStagging(docs, df2)\n",
    "df2 = KB_detection(docs, df2, kb)\n",
    "\n",
    "\n",
    "#add emotions\n",
    "df2 = emotions_nrc(docs, df2)\n",
    "\n",
    "\n",
    "#readability and difficulty\n",
    "df2 = readability_and_difficulty_scores(titels, df2)\n",
    "\n",
    "\n",
    "#grammar and spelling errors\n",
    "df2 = Error_check(titels, df2)\n",
    "\n",
    "\n",
    "df = concat_df(df, df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40946f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparation (df: pd.DataFrame, csv_path_labels: str, labelname: str) -> tuple[pd.Series, pd.DataFrame]:\n",
    "\n",
    "    \"\"\" \n",
    "        preparing the df for the ML part\n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "\n",
    "    df = df.drop(columns = [\"Unnamed: 0\", \"Index\", \"hl_Index\", \"Text\", \"Title\", \"hl_Title\", \"hl_Text\"])\n",
    "\n",
    "    #prepare x and y  \n",
    "    x = df \n",
    "    real_fake = pd.read_csv(csv_path_labels)\n",
    "    y = pd.Series(real_fake[labelname], name = labelname)\n",
    "  \n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def grid_search_rf(x: pd.DataFrame, y: pd.Series, seed: int) -> RandomForestClassifier: \n",
    "\n",
    "    \"\"\" \n",
    "        param optimazation with grid search\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    params = {\n",
    "\n",
    "            \"n_estimators\": [100, 110, 120, 130, 140, 150, 160, 170, 180, 190],\n",
    "            \"max_depth\": [None, 5, 10, 15, 20],\n",
    "            \"min_samples_leaf\": [2, 3, 4, 5, 6],\n",
    "            \"max_features\": [\"sqrt\", 0.3, 0.5]\n",
    "\n",
    "        }\n",
    "\n",
    "\n",
    "    #finding the best params for our temp random forrest (accr. metric to beat the score)\n",
    "    rf = RandomForestClassifier(random_state = seed, n_jobs = -1)\n",
    "    opt_grid = GridSearchCV(rf, params, cv = RepeatedStratifiedKFold(n_splits = 5,\n",
    "                            n_repeats = 3, random_state = seed), scoring = \"accuracy\",\n",
    "                            n_jobs = -1)\n",
    "    opt_grid.fit(x, y)\n",
    "\n",
    "\n",
    "    return opt_grid.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def data_filter (x: pd.DataFrame, y: pd.Series, seed: int) -> tuple[pd.DataFrame, pd.DataFrame,\n",
    "                                                                    pd.Series, pd.Series, list[str]]:\n",
    "\n",
    "    \"\"\"\n",
    "        80/20 split and preparation for the final model\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # spliting the dataset\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y, test_size = 0.2, stratify = y, random_state = seed)\n",
    "    \n",
    "\n",
    "    \n",
    "    #extracting params\n",
    "    rf = grid_search_rf(x_train, y_train, seed)\n",
    "\n",
    "\n",
    "    #boruta selection of features \n",
    "    boruta = BorutaPy(estimator = rf, n_estimators = \"auto\", perc = 90, alpha = 0.05, \n",
    "                      max_iter = 70, random_state = seed, verbose = 0)\n",
    "    boruta.fit(x_train, y_train)\n",
    "    selected = [name for name, keep in zip(x_train.columns, boruta.support_) if keep]\n",
    "\n",
    "\n",
    "\n",
    "    #reduction of the subsets\n",
    "    x_train_sel = x_train[selected]\n",
    "    x_test_sel = x_test[selected]\n",
    "\n",
    "  \n",
    "    print(f\"Final features: {selected}\")\n",
    "    print(f\"Features len: {len(selected)}\")\n",
    "    return x_train_sel, x_test_sel, y_train, y_test, selected\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def final_step (x_train_sel: pd.DataFrame, x_test_sel: pd.DataFrame, y_train: pd.Series,\n",
    "                y_test: pd.Series, seed:int) -> RandomForestClassifier:\n",
    "\n",
    "    \"\"\" \n",
    "        Building the last model and report\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    rf_final = grid_search_rf(x_train_sel, y_train, seed = seed)\n",
    "    final_model = rf_final.fit(x_train_sel, y_train)\n",
    "    y_pred = final_model.predict(x_test_sel)\n",
    "    report = classification_report(y_test, y_pred, output_dict = True)\n",
    "\n",
    "\n",
    "    print(f\"Test performance(initial model): {report}\")\n",
    "    return final_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(x: pd.DataFrame, y: pd.Series, features: list[str], rf_model: RandomForestClassifier, seed: int) -> None:\n",
    "\n",
    "    \"\"\" \n",
    "        Here we evaluate our models and the importance of the feats. over 1000 random seeds\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    #evaluation over 1000 seeds\n",
    "    random.seed(seed)\n",
    "    split_seeds = random.sample(range(50, 10001), 1000)\n",
    "\n",
    "    accuracies = []\n",
    "    recalls = []\n",
    "    precision = []\n",
    "    f1s = []\n",
    "    feat_imp = []\n",
    "\n",
    "    accuracies_base = []\n",
    "    recalls_base = []\n",
    "    precision_base = []\n",
    "    f1s_base = []\n",
    "\n",
    "    rf_params = rf_model.get_params()\n",
    "    rf_params.pop(\"random_state\")\n",
    "\n",
    "\n",
    "    for rs in split_seeds:\n",
    "        x_tr, x_te, y_tr, y_te = train_test_split(x[features], y, test_size = 0.2, stratify = y,\n",
    "                                                  random_state = rs)\n",
    "\n",
    "        rf = RandomForestClassifier(**rf_params, random_state = rs)\n",
    "        rf.fit(x_tr, y_tr)\n",
    "        y_pred = rf.predict(x_te)\n",
    "\n",
    "\n",
    "        rpt = classification_report(y_te, y_pred, output_dict = True)\n",
    "        accuracies.append(rpt[\"accuracy\"])\n",
    "        recalls.append(rpt[\"macro avg\"][\"recall\"])\n",
    "        precision.append(rpt[\"macro avg\"][\"precision\"])\n",
    "        f1s.append(rpt[\"macro avg\"][\"f1-score\"])\n",
    "\n",
    "        feat_imp.append(rf.feature_importances_)\n",
    "\n",
    "        #extra baselinemodel\n",
    "        dummy_compare = DummyClassifier(strategy = \"stratified\", random_state = rs)\n",
    "        dummy_compare.fit(x_tr, y_tr)\n",
    "        y_pred_dummy = dummy_compare.predict(x_te)\n",
    "\n",
    "\n",
    "        rpt_dummy = classification_report(y_te, y_pred_dummy, output_dict = True)\n",
    "        accuracies_base.append(rpt_dummy[\"accuracy\"])\n",
    "        recalls_base.append(rpt_dummy[\"macro avg\"][\"recall\"])\n",
    "        precision_base.append(rpt_dummy[\"macro avg\"][\"precision\"])\n",
    "        f1s_base.append(rpt_dummy[\"macro avg\"][\"f1-score\"])\n",
    "\n",
    "\n",
    "    #95%-CI\n",
    "    root_n = np.sqrt(1000)\n",
    "    ci_acc_plus = np.mean(accuracies) + 1.96 * (np.std(accuracies, ddof = 1) / root_n)\n",
    "    ci_acc_minus = np.mean(accuracies) - 1.96 * (np.std(accuracies, ddof = 1) / root_n)\n",
    "\n",
    "    ci_rec_plus = np.mean(recalls) + 1.96 * (np.std(recalls, ddof = 1) / root_n)\n",
    "    ci_rec_minus = np.mean(recalls) - 1.96 * (np.std(recalls, ddof = 1) / root_n)\n",
    "\n",
    "    ci_prec_plus = np.mean(precision) + 1.96 * (np.std(precision, ddof = 1) / root_n)\n",
    "    ci_prec_minus = np.mean(precision) - 1.96 * (np.std(precision, ddof = 1) / root_n)\n",
    "\n",
    "    ci_f1s_plus = np.mean(f1s) + 1.96 * (np.std(f1s, ddof = 1) / root_n)\n",
    "    ci_f1s_minus = np.mean(f1s) - 1.96 * (np.std(f1s, ddof = 1) / root_n)\n",
    "\n",
    "\n",
    "    ci_acc_base_plus = np.mean(accuracies_base) + 1.96 * (np.std(accuracies_base, ddof = 1) / root_n)\n",
    "    ci_acc_base_minus = np.mean(accuracies_base) - 1.96 * (np.std(accuracies_base, ddof = 1) / root_n)\n",
    "\n",
    "    ci_rec_base_plus = np.mean(recalls_base) + 1.96 * (np.std(recalls_base, ddof = 1) / root_n)\n",
    "    ci_rec_base_minus = np.mean(recalls_base) - 1.96 * (np.std(recalls_base, ddof = 1) / root_n)\n",
    "\n",
    "    ci_prec_base_plus = np.mean(precision_base) + 1.96 * (np.std(precision_base, ddof = 1) / root_n)\n",
    "    ci_prec_base_minus = np.mean(precision_base) - 1.96 * (np.std(precision_base, ddof = 1) / root_n)\n",
    "\n",
    "    ci_f1s_base_plus = np.mean(f1s_base) + 1.96 * (np.std(f1s_base, ddof = 1) / root_n)\n",
    "    ci_f1s_base_minus = np.mean(f1s_base) - 1.96 * (np.std(f1s_base, ddof = 1) / root_n)    \n",
    "    \n",
    "\n",
    "    feat_imp = pd.Series(np.mean(feat_imp, axis = 0), index = features).sort_values(ascending = False)\n",
    "\n",
    "    relevant_keys = [\"n_estimators\", \"max_depth\", \"min_samples_leaf\", \"max_features\", \"criterion\"]\n",
    "    rf_params = {key: value for key, value in rf_params.items() if key in relevant_keys}\n",
    "    rf_params = pd.Series(rf_params).sort_index()\n",
    "   \n",
    "    print(\"\\n\\n---Random Forrest Classifier Params---\")\n",
    "    print(pd.Series(rf_params).sort_index())\n",
    "\n",
    "    print(\"\\n\\n---For the Random Forrest Classifier---\")\n",
    "    print(f\"Accuracy = {np.mean(accuracies): .3f} ± {np.std(accuracies): .3f} (95% CI [{ci_acc_minus: .3f} - {ci_acc_plus: .3f}]) \")\n",
    "    print(f\"Recall = {np.mean(recalls): .3f} ± {np.std(recalls):.3f} (95% CI [{ci_rec_minus: .3f} - {ci_rec_plus: .3f}])\")\n",
    "    print(f\"Precision = {np.mean(precision): .3f} ± {np.std(precision): .3f} (95% CI [{ci_prec_minus: .3f} - {ci_prec_plus: .3f}])\")\n",
    "    print(f\"F1-Score = {np.mean(f1s): .3f} ± {np.std(f1s): .3f} (95% CI [{ci_f1s_minus: .3f} - {ci_f1s_plus: .3f}])\")\n",
    "\n",
    "    print(\"\\n\\n---For the Baseline---\")\n",
    "    print(f\"Accuracy = {np.mean(accuracies_base): .3f} ± {np.std(accuracies_base): .3f} (95% CI [{ci_acc_base_minus: .3f} - {ci_acc_base_plus: .3f}])\")\n",
    "    print(f\"Recall = {np.mean(recalls_base): .3f} ± {np.std(recalls_base): .3f} (95% CI [{ci_rec_base_minus: .3f} - {ci_rec_base_plus: .3f}])\")\n",
    "    print(f\"Precision = {np.mean(precision_base): .3f} ± {np.std(precision_base): .3f} (95% CI [{ci_prec_base_minus: .3f} - {ci_prec_base_plus: .3f}])\")\n",
    "    print(f\"F1-Score = {np.mean(f1s_base): .3f} ± {np.std(f1s_base): .3f} (95% CI [{ci_f1s_base_minus: .3f} - {ci_f1s_base_plus: .3f}])\")\n",
    "\n",
    "    print(\"\\n\\n---Feature importance---\")\n",
    "    print(feat_imp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efdd81d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\ma\\core.py:2892: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final features: ['adj_perc', 'noun_perc', 'pron_perc', 'propn_perc', 'sconj_perc', 'verb_perc', 'fake_match_count', 'anticipation_perc', 'hl_noun_perc', 'hl_propn_perc', 'hl_punct_perc', 'hl_verb_perc', 'hl_automated_readbility_index']\n",
      "Features len: 13\n",
      "Test performance(initial model): {'no': {'precision': 0.9285714285714286, 'recall': 0.9285714285714286, 'f1-score': 0.9285714285714286, 'support': 14.0}, 'yes': {'precision': 0.9375, 'recall': 0.9375, 'f1-score': 0.9375, 'support': 16.0}, 'accuracy': 0.9333333333333333, 'macro avg': {'precision': 0.9330357142857143, 'recall': 0.9330357142857143, 'f1-score': 0.9330357142857143, 'support': 30.0}, 'weighted avg': {'precision': 0.9333333333333333, 'recall': 0.9333333333333333, 'f1-score': 0.9333333333333333, 'support': 30.0}}\n",
      "\n",
      "\n",
      "---Random Forrest Classifier Params---\n",
      "criterion           gini\n",
      "max_depth              5\n",
      "max_features        sqrt\n",
      "min_samples_leaf       2\n",
      "n_estimators         190\n",
      "dtype: object\n",
      "\n",
      "\n",
      "---For the Random Forrest Classifier---\n",
      "Accuracy =  0.840 ±  0.067 (95% CI [ 0.836 -  0.845]) \n",
      "Recall =  0.839 ± 0.068 (95% CI [ 0.835 -  0.843])\n",
      "Precision =  0.847 ±  0.066 (95% CI [ 0.843 -  0.851])\n",
      "F1-Score =  0.838 ±  0.068 (95% CI [ 0.834 -  0.843])\n",
      "\n",
      "\n",
      "---For the Baseline---\n",
      "Accuracy =  0.506 ±  0.093 (95% CI [ 0.500 -  0.512])\n",
      "Recall =  0.504 ±  0.093 (95% CI [ 0.498 -  0.510])\n",
      "Precision =  0.505 ±  0.097 (95% CI [ 0.499 -  0.511])\n",
      "F1-Score =  0.500 ±  0.094 (95% CI [ 0.494 -  0.506])\n",
      "\n",
      "\n",
      "---Feature importance---\n",
      "hl_propn_perc                    0.167952\n",
      "hl_noun_perc                     0.129019\n",
      "hl_verb_perc                     0.076558\n",
      "anticipation_perc                0.076065\n",
      "sconj_perc                       0.072799\n",
      "hl_punct_perc                    0.069452\n",
      "adj_perc                         0.068858\n",
      "verb_perc                        0.066827\n",
      "hl_automated_readbility_index    0.064239\n",
      "noun_perc                        0.059161\n",
      "propn_perc                       0.053400\n",
      "pron_perc                        0.048626\n",
      "fake_match_count                 0.047045\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#to safe some time we use output_features_full.csv which are all features we ectracted above\n",
    "\n",
    "df = pd.read_csv(\"output_features_full.csv\")\n",
    "csv_path_labels = \"group58_stage1.csv\"\n",
    "label = \"real_news\"\n",
    "seed = 37\n",
    "\n",
    "\n",
    "#preparing the data\n",
    "x, y = preparation(df, csv_path_labels, label)\n",
    "\n",
    "\n",
    "#spliting the data in 80/20 and optimize params + feat\n",
    "x_train_sel, x_test_sel, y_train, y_test, features = data_filter(x, y, seed = seed)\n",
    "\n",
    "\n",
    "#building the final model and report\n",
    "final_model= final_step(x_train_sel, x_test_sel, y_train, y_test, seed = seed)\n",
    "\n",
    "\n",
    "#here we evaluate our mode\n",
    "evaluate_model(x, y, features, final_model, seed = seed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
